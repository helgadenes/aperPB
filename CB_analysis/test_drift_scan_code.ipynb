{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test drift scan code\n",
    "- this notebook can be used for debugging and testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "\n",
    "from argparse import ArgumentParser, RawTextHelpFormatter\n",
    "from astropy.coordinates import SkyCoord, FK5\n",
    "from astropy.io import fits\n",
    "from astropy.time import Time\n",
    "from astropy.table import Table\n",
    "import astropy.units as u\n",
    "from astropy.wcs import WCS\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "import time\n",
    "from bisect import bisect_left\n",
    "from astropy.io import ascii\n",
    "\n",
    "from drift_analysis.modules.telescope_params import westerbork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_id2equinox(task_id):\n",
    "\n",
    "    # Automatically take the date of the observaitons from the task_id to calculate apparent coordinates of calibrator\n",
    "    year = 2000 + int(str(task_id)[0:2])\n",
    "    month = str(task_id)[2:4]\n",
    "    day = str(task_id)[4:6]\n",
    "    equinox = Time('{}-{}-{}'.format(year, month, day))\n",
    "\n",
    "    return equinox.decimalyear\n",
    "\n",
    "def take_closest(myList, myNumber):\n",
    "    \"\"\"\n",
    "    Assumes myList is sorted. Returns closest value to myNumber.\n",
    "\n",
    "    If two numbers are equally close, return the smallest number.\n",
    "    \"\"\"\n",
    "    pos = bisect_left(myList, myNumber)\n",
    "    myList.sort()\n",
    "    if pos == 0:\n",
    "        return myList[0]\n",
    "    if pos == len(myList):\n",
    "        return myList[-1]\n",
    "    before = myList[pos - 1]\n",
    "    after = myList[pos]\n",
    "    if after - myNumber < myNumber - before:\n",
    "       return pos - 1\n",
    "    else:\n",
    "       return pos\n",
    "\n",
    "def make_gifs(root):\n",
    "\n",
    "    os.system('convert -delay 50 {}*db0_reconstructed.png {}all_beams0.gif'.format(root, root))\n",
    "    os.system('convert -delay 50 {}*_difference.png {}diff_xx-yy.gif'.format(root, root))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading in all the data...\n"
     ]
    }
   ],
   "source": [
    "#start = time.time()\n",
    "\n",
    "beam_range = [0,39]\n",
    "beams = range(int(beam_range[0]), int(beam_range[1])+1)\n",
    "freqchunks = 10\n",
    "date = '201028'\n",
    "\n",
    "#print(beams)\n",
    "\n",
    "basedir = '/tank/apertif/driftscans/'\n",
    "\n",
    "#with open('drift_analysis/task_id_lists/task_ids_{}.txt'.format(date)) as f:\n",
    "with open('drift_analysis/task_id_lists/task_ids_{}_casa.txt'.format(date)) as f:\n",
    "    task_id = f.read().splitlines()\t\n",
    "\n",
    "np.warnings.filterwarnings('ignore')\n",
    "\n",
    "radec = ascii.read('/home/denes/pattern39+1.txt')\n",
    "\n",
    "\n",
    "# Find calibrator position\n",
    "calib_name = 'Cas A'\n",
    "calib = SkyCoord.from_name('Cas A')\n",
    "\n",
    "cell_size = 100. / 3600.\n",
    "l = len(task_id)\n",
    "\n",
    "# Make a list of data tables (the csv tables with the auto correlations).\n",
    "datafiles, posfiles = [], []\n",
    "\n",
    "for i in range(len(task_id)):\n",
    "    datafiles.append('{}{}/{}_exported_data_frequency_split.csv'.format(basedir, task_id[i], task_id[i]))\n",
    "    posfiles.append('{}{}/{}_hadec.csv'.format(basedir, task_id[i], task_id[i]))\n",
    "\n",
    "#datafiles.sort()\n",
    "#posfiles.sort()\n",
    "#print(datafiles)\n",
    "\n",
    "# Put calibrator into apparent coordinates (because that is what the telescope observes it in.)\n",
    "test = calib.transform_to('fk5')\n",
    "calibnow = test.transform_to(FK5(equinox='J{}'.format(task_id2equinox(task_id[0]))))\n",
    "\n",
    "# Read data from tables\n",
    "data_tab, hadec_tab = [], []\n",
    "print(\"\\nReading in all the data...\")\n",
    "for file, pos in zip(datafiles, posfiles):\n",
    "    data_tab.append(Table.read(file, format='csv'))  # list of tables\n",
    "    hadec_tab.append(Table.read(pos, format='csv'))  # list of tables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "beams = range(0,40)\n",
    "#calib_name = 'Cyg A'\n",
    "calib_name = 'Cas A'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making beam maps: \n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "print(\"Making beam maps: \")\n",
    "for beam in beams:\n",
    "    print(beam)\n",
    "\n",
    "    for f in range(freqchunks):\n",
    "        x, y, z_xx, z_yy = [], [], [], []\n",
    "        decs = []\n",
    "\n",
    "        for data, hadec, i in zip(data_tab, hadec_tab, range(len(data_tab))):\n",
    "            calibnow = test.transform_to(FK5(equinox='J{}'.format(task_id2equinox(task_id[i]))))\n",
    "\n",
    "            hadec_start = SkyCoord(ra=hadec['ha'], dec=hadec['dec'], unit=(u.rad, u.rad))\n",
    "            time_mjd = Time(data['time'] / (3600 * 24), format='mjd')\n",
    "            time_mjd.delta_ut1_utc = 0  # extra line to compensate for missing icrs tables\n",
    "            lst = time_mjd.sidereal_time('apparent', westerbork().lon)\n",
    "\n",
    "            HAcal = lst - calibnow.ra  # in sky coords\n",
    "            dHAsky = HAcal - hadec_start[beam].ra + (24 * u.hourangle)  # in sky coords in hours\n",
    "            dHAsky.wrap_at('180d', inplace=True)\n",
    "            dHAphys = dHAsky * np.cos(hadec_start[beam].dec.deg * u.deg)  # physical offset in hours\n",
    "\n",
    "            x = np.append(x, dHAphys.deg)\n",
    "            y = np.append(y, np.full(len(dHAphys.deg), hadec_start[beam].dec.deg))  # the drift scan sampling is not uniform on the top of the field, linspace squashes the top beams \n",
    "            z_xx = np.append(z_xx, data['auto_corr_beam_{}_freq_{}_xx'.format(beam, f)] - np.median(\n",
    "                data['auto_corr_beam_{}_freq_{}_xx'.format(beam, f)]))\n",
    "            z_yy = np.append(z_yy, data['auto_corr_beam_{}_freq_{}_yy'.format(beam, f)] - np.median(\n",
    "                data['auto_corr_beam_{}_freq_{}_yy'.format(beam, f)]))\n",
    "\n",
    "        # Create the 2D plane, do a cubic interpolation, and append it to the cube.\n",
    "        tx = np.arange(min(x), max(x), cell_size)\n",
    "        ty = np.arange(min(y), max(y), cell_size)\n",
    "        XI, YI = np.meshgrid(tx, ty)\n",
    "        #print(len(ty))\n",
    "        #gridcubx = np.flipud(interpolate.griddata((x, y), z_xx, (XI, YI), method='cubic'))  # median already subtracted\n",
    "        #gridcuby = np.flipud(interpolate.griddata((x, y), z_yy, (XI, YI), method='cubic'))\n",
    "        gridcubx = interpolate.griddata((x, y), z_xx, (XI, YI), method='cubic')  # median already subtracted\n",
    "        gridcuby = interpolate.griddata((x, y), z_yy, (XI, YI), method='cubic')\n",
    "\n",
    "\n",
    "        # Find the reference pixel at the apparent coordinates of the calibrator\n",
    "        #ref_pixy = (calibnow.dec.deg - y[0]) / cell_size + 1  # FITS indexed from 1\n",
    "        calibnow = test.transform_to(FK5(equinox='J{}'.format(task_id2equinox(task_id[0]))))\n",
    "        ref_pixx = (-min(x)) / cell_size + 1                        # FITS indexed from 1\n",
    "        ref_pixy = (calibnow.dec.deg - min(y)) / cell_size + 1   \n",
    "        ref_pixz = 1                                                # FITS indexed from 1\n",
    "\n",
    "        # Find the peak of the primary beam to normalize\n",
    "        norm_xx = np.max(gridcubx[int(ref_pixy) - 3:int(ref_pixy) + 4, int(ref_pixx) - 3:int(ref_pixx) + 4])\n",
    "        norm_yy = np.max(gridcuby[int(ref_pixy) - 3:int(ref_pixy) + 4, int(ref_pixx) - 3:int(ref_pixx) + 4])\n",
    "\n",
    "        # Create 3D array with proper size for given scan set to save data as a cube\n",
    "        if f == 0:\n",
    "            cube_xx = np.zeros((freqchunks, gridcubx.shape[0], gridcubx.shape[1]))\n",
    "            cube_yy = np.zeros((freqchunks, gridcuby.shape[0], gridcuby.shape[1]))\n",
    "            db_xx = np.zeros((freqchunks, gridcubx.shape[0], gridcubx.shape[1]))\n",
    "            db_yy = np.zeros((freqchunks, gridcuby.shape[0], gridcuby.shape[1]))\n",
    "\n",
    "        cube_xx[f, :, :] = gridcubx/norm_xx\n",
    "        cube_yy[f, :, :] = gridcuby/norm_yy\n",
    "\n",
    "        # Convert to decibels\n",
    "        db_xx[f, :, :] = np.log10(gridcubx/norm_xx) * 10.\n",
    "        db_yy[f, :, :] = np.log10(gridcuby/norm_yy) * 10.\n",
    "\n",
    "    stokesI = np.sqrt(0.5 * cube_yy**2 + 0.5 * cube_xx**2)\n",
    "    squint = cube_xx - cube_yy\n",
    "\n",
    "    wcs = WCS(naxis=3)\n",
    "    wcs.wcs.cdelt = np.array([-cell_size, cell_size, 12.207e3*1500])\n",
    "    wcs.wcs.ctype = ['RA---TAN', 'DEC--TAN', 'FREQ']\n",
    "    wcs.wcs.crval = [calib.ra.to_value(u.deg), calib.dec.to_value(u.deg), 1219.609e6+(12.207e3*(500+1500/2))]\n",
    "    wcs.wcs.crpix = [ref_pixx, ref_pixy, ref_pixz]\n",
    "    wcs.wcs.specsys = 'TOPOCENT'\n",
    "    wcs.wcs.restfrq = 1.420405752e+9\n",
    "    header = wcs.to_header()\n",
    "\n",
    "    hdux = fits.PrimaryHDU(cube_xx, header=header)\n",
    "    hduy = fits.PrimaryHDU(cube_yy, header=header)\n",
    "    hduI = fits.PrimaryHDU(stokesI, header=header)\n",
    "    hdusq = fits.PrimaryHDU(squint, header=header)\n",
    "\n",
    "    if not os.path.exists(basedir + 'fits_files/{}/'.format(date)):\n",
    "        os.mkdir(basedir + 'fits_files/{}/'.format(date))\n",
    "\n",
    "    # Save the FITS files\n",
    "    hdux.writeto(basedir + 'fits_files/{}/{}_{}_{:02}_xx.fits'.format(date, calib_name.replace(\" \", \"\"), date,\n",
    "                                                         beam), overwrite=True)\n",
    "    hduy.writeto(basedir + 'fits_files/{}/{}_{}_{:02}_yy.fits'.format(date, calib_name.replace(\" \", \"\"), date,\n",
    "                                                         beam), overwrite=True)\n",
    "    hduI.writeto(basedir + 'fits_files/{}/{}_{}_{:02}_I.fits'.format(date, calib_name.replace(\" \", \"\"), date,\n",
    "                                                         beam), overwrite=True)\n",
    "    hdusq.writeto(basedir + 'fits_files/{}/{}_{}_{:02}_diff.fits'.format(date, calib_name.replace(\" \", \"\"), date,\n",
    "                                                             beam), overwrite=True)\n",
    "\n",
    "#end = time.time()\n",
    "#print('Time [minutes]: ', (end - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
