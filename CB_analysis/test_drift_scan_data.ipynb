{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "\n",
    "from argparse import ArgumentParser, RawTextHelpFormatter\n",
    "from astropy.coordinates import SkyCoord, FK5\n",
    "from astropy.io import fits\n",
    "from astropy.time import Time\n",
    "from astropy.table import Table\n",
    "import astropy.units as u\n",
    "from astropy.wcs import WCS\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "import time\n",
    "from bisect import bisect_left\n",
    "from astropy.io import ascii\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beams = range(0, 40)\n",
    "date = '200819'\n",
    "\n",
    "basedir = '/tank/apertif/driftscans/'\n",
    "task_ids = './drift_analysis/task_id_lists/task_ids_200819.txt'\n",
    "\n",
    "with open(task_ids) as f:\n",
    "    task_id = f.read().splitlines()\t\n",
    "\n",
    "np.warnings.filterwarnings('ignore')\n",
    "\n",
    "# Make a list of data tables (the csv tables with the auto correlations).\n",
    "datafiles, posfiles = [], []\n",
    "\n",
    "for i in range(len(task_id)):\n",
    "    datafiles.append('{}{}/{}_exported_data_frequency_split.csv'.format(basedir, task_id[i], task_id[i]))\n",
    "    posfiles.append('{}{}/{}_hadec.csv'.format(basedir, task_id[i], task_id[i]))\n",
    "    \n",
    "data_tab, hadec_tab = [], []\n",
    "print(\"\\nReading in all the data...\")\n",
    "data = Table.read(datafiles[0], format='csv')\n",
    "data2 = Table.read(datafiles[1], format='csv')\n",
    "data3 = Table.read(datafiles[2], format='csv')\n",
    "data4 = Table.read(datafiles[3], format='csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_xx_1 = []\n",
    "z_xx_2 = []\n",
    "z_xx_3 = []\n",
    "z_xx_4 = []\n",
    "\n",
    "beam = '1'\n",
    "f = '5'\n",
    "for f in range(0,10):\n",
    "    z_xx_1.append(np.array(data['auto_corr_beam_{}_freq_{}_xx'.format(beam, f)] - np.median(data['auto_corr_beam_{}_freq_{}_xx'.format(beam, f)])))\n",
    "    z_xx_2.append(np.array(data2['auto_corr_beam_{}_freq_{}_xx'.format(beam, f)] - np.median(data2['auto_corr_beam_{}_freq_{}_xx'.format(beam, f)])))\n",
    "    z_xx_3.append(np.array(data3['auto_corr_beam_{}_freq_{}_xx'.format(beam, f)] - np.median(data3['auto_corr_beam_{}_freq_{}_xx'.format(beam, f)])))\n",
    "    z_xx_4.append(np.array(data4['auto_corr_beam_{}_freq_{}_xx'.format(beam, f)] - np.median(data4['auto_corr_beam_{}_freq_{}_xx'.format(beam, f)])))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "    plt.plot(range(len(z_xx[i])), z_xx[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(z_xx[0])), z_xx[0])\n",
    "plt.plot(range(len(z_xx_2[0])), z_xx_2[0])\n",
    "plt.plot(range(len(z_xx_3[0])), z_xx_3[0])\n",
    "plt.plot(range(len(z_xx_4[0])), z_xx_4[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
